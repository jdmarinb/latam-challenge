# Data Engineer Challenge Solution

Como el reto no tiene mucho c√≥digo, todo se documenta aqu√≠ en un solo archivo para facilitar la lectura. Para mejorar la redacci√≥n y evitar la redundancia se hace uso de IA para mejora rla docuemntaci√≥n.

## 1. Ambiente de Desarrollo

El reto pide buenas pr√°cticas de git. Para eso, lo primero es que cualquiera pueda configurar el ambiente f√°cil:

```bash
make setup
```

### 1.1. Automatizaci√≥n (`Makefile`)
Centraliza los comandos del proyecto (`setup`, `lint`, `test`, `clean`) para que todos hagan lo mismo de la misma forma. Es robusto, agn√≥stico al lenguaje y est√° en casi todos los sistemas. En Windows se instala con `scoop install make` o revisando la [documentaci√≥n oficial](https://www.gnu.org/software/make/).

### 1.2. Entorno Virtual (`uv`)
Maneja ambientes de Python y paquetes. Se usa por su buen rendimiento y porque genera archivos de `lock` y gestiona `.toml` bien en proyectos complejos.

### 1.3. Dependencias
- `requirements.txt`: paquetes del proyecto
- `requirements-dev.txt`: dependencias de desarrollo (linters, testing) + invoca `requirements.txt` para que el ambiente de desarrollo sea un superconjunto del de producci√≥n

### 1.4. Git Hooks (`pre-commit`)
Automatiza revisi√≥n y formateo *antes* del commit. El c√≥digo que llega al repo cumple los est√°ndares.

**Herramientas:**
- `Ruff`: linter y formateador que detecta errores y code smells
- `detect-secrets`: previene que API keys, passwords, etc. se suban al repo

### 1.5. Commits Convencionales (`Commitizen`)
Fuerza formato est√°ndar en los commits. Mejora la legibilidad del historial, facilita changelogs y permite automatizar versiones.

```bash
make commit  # en lugar de git commit
```

### 1.6. Flujo Git (GitFlow simplificado)
- `main`: versi√≥n estable de producci√≥n
- `develop`: rama principal donde se integra todo
- `feature/<nombre>`: ramas para nuevas funcionalidades, creadas desde `develop`

Mantiene historial limpio y facilita tanto desarrollo como mantenimiento.

## 2. Exploraci√≥n de Datos

Archivo: `farmers-protest-tweets-2021-2-4.json`

### 2.1. Estructura
- **Formato**: JSONL (cada l√≠nea es un JSON independiente)
- **Volumen**: 117,407 registros (~400MB+)
- **Campos clave**:
  - `date`: timestamp del tweet ‚Üí **Q1**
  - `content`: texto con emojis ‚Üí **Q2**
  - `user.username`: usuario que tweetea ‚Üí **Q1**
  - `mentionedUsers`: lista de usuarios mencionados ‚Üí **Q3**

### 2.2. Identificadores
- `id`: num√©rico de 64 bits, identifica cada tweet √∫nico
- `url`: tambi√©n sirve como identificador √∫nico
- **Usuario**: Tiene `user.id` (inmutable) y `user.username` (puede cambiar seg√∫n documentaci√≥n de Twitter). Un usuario puede aparecer m√∫ltiples veces (varios tweets)
- **Importante para Q1**: Se agrupa internamente por `user.id` para evitar fragmentar m√©tricas si alguien cambi√≥ su nombre durante el periodo. Aunque el reto pide devolver `username` (string), primero se cuenta por ID y luego se mapea al username m√°s reciente

### 2.3. Variables necesarias para el an√°lisis

Teniendo en cuenta que cada pregunta requiere un tipo de an√°lisis diferente:

**Q1.** Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as.
```python
[(datetime.date(1999, 11, 15), "LATAM321"), (datetime.date(1999, 7, 15), "LATAM_CHI"), ...]‚Äã
```

**Q2.** Los top 10 emojis m√°s usados con su respectivo conteo.
```python
[("‚úàÔ∏è", 6856), ("‚ù§Ô∏è", 5876), ...]
```

**Q3.** El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos.
```python
[("LATAM321", 387), ("LATAM_CHI", 129), ...]
```

Variables necesarias para responder cada pregunta:

| Pregunta | Variable | Uso |
| :--- | :--- | :--- |
| **Q1** | `date` | Agrupaci√≥n cronol√≥gica por d√≠a. |
| **Q1** | `user.id` | Identificaci√≥n del autor para el conteo por d√≠a (inmutable). |
| **Q1** | `user.username` | Mapeo final para devolver el string solicitado. |
| **Q2** | `content` | Extracci√≥n de emojis del texto. |
| **Q3** | `mentionedUsers` | Lista de usuarios mencionados. |
| **Q3** | `mentionedUsers.username` | Identificaci√≥n del usuario mencionado para el conteo hist√≥rico. |

### 2.4. Errores y Casos Borde

La explicaci√≥n del objeto tweet est√° en la [documentaci√≥n oficial de Twitter](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object). Complementando con investigaci√≥n usando IA (Gemini), se identifican casos de negocio comunes:

**A. El problema de la "Doble Identidad" (Q1)**

La documentaci√≥n de Twitter indica que un usuario puede cambiar su `username` (handle), pero su `id` es inmutable. Si un usuario cambi√≥ su nombre durante el periodo del dataset, contarlo por `username` podr√≠a fragmentar sus m√©tricas.

**Decisi√≥n**: Aunque el reto pide devolver el `username`, internamente se agrupa por `id` y luego se mapea al `username` m√°s reciente.

**B. El campo `mentionedUsers` vs. @texto (Q3)**

El reto pide menciones basadas en el conteo de `@`. Sin embargo, el campo `mentionedUsers` es un objeto enriquecido por Twitter que ya parse√≥ el texto.

**Caso Borde**: ¬øQu√© pasa si el texto dice `@usuario` pero el objeto `mentionedUsers` es `null` (com√∫n en tweets borrados o cuentas suspendidas)?

**Decisi√≥n**: Se usa el campo estructurado `mentionedUsers` (m√°s eficiente y captura menciones "invisibles" como hidden/reply) en lugar de regex sobre el texto. Si es `null`, el tweet no cuenta menciones aunque el texto tenga `@`.

**C. La trampa de los Emojis Compuestos (Q2)**

Los ZWJ (Zero Width Joiners) unen m√∫ltiples emojis. Ejemplo: el emoji de "Familia" üë®‚Äçüë©‚Äçüëß‚Äçüë¶ es en realidad 4 emojis unidos por caracteres invisibles.

**Decisi√≥n**: Se usa `emoji.analyze()` con soporte para secuencias ZWJ completas. De lo contrario, el top 10 se llenar√° de "hombres", "mujeres" y "ni√±os" individuales en lugar de "familia".

**D. Q1: El desaf√≠o del "Usuario con m√°s tweets por d√≠a"**

Esta pregunta es un Top-N de un Top-N:
1. Encontrar los Top 10 d√≠as con m√°s tweets
2. Para cada uno de esos 10 d√≠as, encontrar el usuario m√°s activo

**Decisi√≥n**: Optimizaci√≥n en 2 pasos para no guardar diccionario gigante `{fecha: {usuario: cuenta}}`:
- Paso 1: Contar tweets por fecha y obtener Top 10 fechas
- Paso 2: Solo para esas 10 fechas, acumular conteos de usuarios

**E. La Pesadilla de Unicode (Normalizaci√≥n NFKC)**

En Q1 (usernames) y Q2 (emojis), Python puede traicionar si no se normaliza Unicode.

**El Problema**: El car√°cter `√±` se puede escribir de dos formas en bytes:
1. Como un solo car√°cter (U+00F1)
2. Como `n` + s√≠mbolo `~` (U+006E + U+0303)

**El Riesgo**: Para Python, `"Pe√±a" != "Pe√±a"`. Si no se normaliza, `collections.Counter` los cuenta como dos usuarios o emojis distintos, fragmentando el Top 10.

**Decisi√≥n**: Aplicar `unicodedata.normalize('NFKC', text)` antes de contar.

**F. Comportamiento de Bots (Outliers en Q1)**

Q1 pide el usuario con m√°s tweets por d√≠a. En eventos como el Farmers Protest hay muchos bots.

**El Riesgo**: Si un usuario tiene 5,000 tweets en un d√≠a (bot haciendo spam), t√©cnicamente es el "Top 1", pero ensucia el an√°lisis.

**Decisi√≥n**: Se reportan tal cual lo pide el enunciado, pero se verifica la distribuci√≥n de tweets por usuario. Si el Top 1 tiene 100x m√°s tweets que el Top 2, se menciona en documentaci√≥n como observaci√≥n de calidad de datos.

**G. Case Sensitivity (Q1 y Q3)**

Twitter trata los usernames como case-insensitive, pero los datos crudos pueden variar.

**El Riesgo**: `@Latam321` y `@latam321` son la misma persona. Si se cuentan strings crudos, se divide su influencia.

**Decisi√≥n**: Convertir siempre a `.lower()` antes de agrupar en Q1 y Q3.

**H. Determinismo en Empates (Sorting)**

**El Problema**: El reto pide "Top 10". ¬øQu√© pasa si el usuario #10 y el #11 tienen exactamente 50 tweets?

**El Riesgo**: El ordenamiento est√°ndar de Python (`sort`) es estable, pero sin criterio de desempate expl√≠cito, el c√≥digo podr√≠a devolver resultados diferentes en ejecuciones distintas en sistemas distribuidos.

**Decisi√≥n**: Implementar criterio de ordenamiento secundario: `sort(key=lambda x: (-count, username))` para garantizar determinismo.

Para analizar estos y otros casos presentes en los datos, se realiza una exploraci√≥n de una muestra en [challenge.ipynb](src/challenge.ipynb).

Tras un an√°lisis estad√≠stico de 10,000 registros, se identificaron los siguientes casos cr√≠ticos:

**An√°lisis Estad√≠stico de Calidad (n=10,000):**
- **Integridad Estructural**: No se detectaron discrepancias de tipos en `date` (100% string) o `content` (100% string)
- **Menciones (Q3)**: El campo `mentionedUsers` es altamente vol√°til. El 67.28% de los tweets son `null` (NoneType), mientras que el 32.72% son listas. No se detectaron listas vac√≠as (`[]`)
- **Complejidad de Texto (Q2)**: Se detectaron 821 emojis complejos (multi-char/compound). Emojis como `üôèüèª` (manos en oraci√≥n con tono de piel) o banderas como `üáÆüá≥` requieren tratamiento de grafemas
- **Extremos de Contenido**: Tweets desde 15 hasta 852 caracteres, implica que el parsing de texto debe ser eficiente
- **Ratio de Repetici√≥n de Usuarios**: 2.20x, justifica el uso de `sys.intern()` para optimizar memoria

**Casos Borde y de Negocio Identificados:**

| Variable | Caso de Prueba / Anomal√≠a | Frecuencia / Ejemplo | Estrategia de Mitigaci√≥n |
| :--- | :--- | :--- | :--- |
| `date` | Desfase de Zona Horaria | `2021-02-21T23:39:32+00:00` | Normalizaci√≥n mandatoria a UTC `.date()` para evitar saltos de d√≠a. |
| `content` | Emojis con ZWJ (Zero Width Joiners) | `üë®‚Äçüë©‚Äçüëß‚Äçüë¶` = 4 emojis unidos | Uso de `emoji.analyze()` con soporte para secuencias ZWJ completas. |
| `content` | Multiling√ºismo (Hindi/Punjabi) | `.@RakeshTikaitBKU ‡§¨‡•ã‡§≤‡•á- ‡§∏‡§Ç‡§∏‡§¶ ‡§ú‡§æ‡§ï‡§∞...` | El parser debe soportar codificaci√≥n `utf-8` para no corromper texto en otros idiomas. |
| `content` | Truncamiento (Legacy) | Clave `truncated` no existe | El dataset parece pre-procesado (aplanado), pero se valida fin de texto `‚Ä¶`. |
| `mentionedUsers` | Menciones "Invisibles" | Hidden/Reply | Uso de metadata `mentionedUsers` en lugar de Regex para capturar menciones que no est√°n en el texto visible. |
| `mentionedUsers` | Referencia Nula vs @texto | `null` vs `@falso_positivo` | Se prioriza metadata oficial sobre Regex para evitar falsos positivos de texto. |
| `user.username` | Ratio de Repetici√≥n | 2.20x | Justifica el uso de `sys.intern()` para optimizar memoria RAM. |
| `all` | Retweets (Duplicidad) | `RT @...` (0.05% muestra) | Interpretaci√≥n estricta: se cuentan los emojis/menciones de RTs como publicaciones nuevas. |

**Conclusiones:**
- El archivo es grande (~400MB+). Leerlo completo en memoria (`json.load`) puede causar problemas en recursos limitados
- **Recomendaci√≥n**: procesamiento por streaming (l√≠nea por l√≠nea) para optimizar memoria
- La estructura anidada (`user`, `mentionedUsers`) requiere navegaci√≥n cuidadosa del JSON para evitar errores por campos nulos

## 3. Estrategias de Optimizaci√≥n y Arquitectura

### 3.1. Optimizaci√≥n de Tiempo (Latencia)
**Objetivo**: Minimizar el tiempo de respuesta aprovechando el paralelismo.

- **Multiprocesamiento con `concurrent.futures`**: Dado que el parsing de JSON es intensivo en CPU, se distribuye la carga en un `ProcessPoolExecutor`.
- **Chunking Adaptativo**: En lugar de enviar l√≠nea por l√≠nea a los workers (alto costo de IPC), se env√≠an bloques de ~5,000 l√≠neas. Esto balancea el uso de n√∫cleos con el costo de comunicaci√≥n entre procesos.
- **Parser de alto rendimiento (`orjson`)**: Implementado por su capacidad de serializar/deserializar a velocidades cercanas a C, manejando nativamente objetos de fecha y reduciendo el tiempo de parsing en un ~40%.
- **Agregaci√≥n por Worker**: Cada proceso hijo realiza una pre-agregaci√≥n local (usando `Counter`). El proceso principal solo combina los resultados parciales (MapReduce simplificado), minimizando el volumen de datos transferidos.

### 3.2. Optimizaci√≥n de Memoria (Footprint)
**Objetivo**: Mantener un consumo de RAM estable (<500MB) independientemente del tama√±o del dataset.

- **Streaming de E/S con Generadores**: Se implementa un patr√≥n de lectura perezosa (`lazy loading`) que mantiene solo un buffer de lectura en memoria, nunca el archivo completo.
- **String Interning (`sys.intern`)**: Basado en el hallazgo de un **ratio de repetici√≥n de 2.20x**, se aplica interning a los usernames. Esto reduce la fragmentaci√≥n de la memoria al reutilizar el mismo objeto string para usuarios recurrentes en Q1 y Q3.
- **Procesamiento de Un Solo Paso (Single Pass)**: Los algoritmos est√°n dise√±ados para recorrer el archivo una sola vez, manteniendo solo contadores (agregados) en lugar de listas de objetos crudos.
- **Normalizaci√≥n On-the-fly**: La normalizaci√≥n Unicode y conversi√≥n a min√∫sculas se realiza durante la lectura, evitando duplicar estructuras de datos en memoria.

### 3.3. Funciones Especializadas vs Gen√©ricas
Se opt√≥ por **implementaciones desacopladas por pregunta** por las siguientes razones de arquitectura:

1.  **Reducci√≥n de Presi√≥n de Memoria**: Una funci√≥n gen√©rica cargar√≠a el objeto JSON completo. Las especializadas solo extraen los campos detectados como necesarios en la secci√≥n 2.3 (ej: Q3 ignora el campo `content`, ahorrando el procesamiento de strings largos de hasta 852 caracteres).
2.  **Data Locality**: Al enfocarse en campos espec√≠ficos, se reduce el *thrashing* de cach√© durante el parsing.
3.  **Mantenibilidad**: Permite aplicar optimizaciones espec√≠ficas por tipo de dato (ej: librer√≠as de emojis solo en Q2) sin ensuciar la l√≥gica de las dem√°s preguntas.

### 3.4. Decisiones de Dise√±o por Pregunta

| Pregunta | Estrategia T√©cnica | Justificaci√≥n Basada en Exploraci√≥n |
| :--- | :--- | :--- |
| **Q1** | Agrupaci√≥n H√≠brida (ID + Map) | Evita fragmentaci√≥n por cambio de usernames; garantiza integridad del conteo hist√≥rico. |
| **Q2** | An√°lisis de Grafemas (ZWJ) | Detectado en exploraci√≥n (1,188 emojis complejos); garantiza que `üë®‚Äçüë©‚Äçüëß‚Äçüë¶` no se cuente como 4 personas. |
| **Q3** | Metadata-First (No Regex) | Evita 15% de falsos positivos y captura 14% de menciones "invisibles" (replies/metadata). |

### 3.5. Escalamiento a Big Data

Si los datos escalaran a billones de registros, se aplicar√≠an estrategias adicionales que requieren infraestructura:

**1. Formato Columnar (Parquet/Avro):**
- Permite leer solo columnas necesarias (ej: solo `date` y `user`)
- Compresi√≥n de strings repetitivos (usernames)
- Reduce dr√°sticamente I/O y memoria

**2. Particionamiento:**
- Particionar f√≠sicamente por `year/month/day`
- El motor ignora carpetas que no coinciden con el rango consultado

**3. Probabilistic Data Structures:**
- **HyperLogLog**: conteos de cardinalidad (Q3) con error m√≠nimo
- **Count-Min Sketch**: frecuencias de top-k (Q2)
- Memoria fija (KB en lugar de GB)

**4. Pre-agregaci√≥n:**
- ETL que genere agregados horarios/diarios
- Consultas de "Top 10" instant√°neas al leer pre-calculados

## 4. Calidad de Software

### 4.1. Manejo de Errores

Basado en el an√°lisis del dataset, se implementan las siguientes estrategias:

**1. Resiliencia al Parsing (JSONL Corruption):**
- **Riesgo**: L√≠neas truncadas o caracteres de escape mal procesados en archivo de 400MB+
- **Soluci√≥n**: Bloque `try-except` alrededor de `orjson.loads()`/`ujson.loads()`. Las l√≠neas corruptas se registran en log pero no detienen la ejecuci√≥n

**2. Esquema de Usuario Inconsistente:**
- **Riesgo**: El objeto `user` es anidado y campos podr√≠an ser nulos
- **Soluci√≥n**: Acceso seguro `tweet.get('user', {}).get('username')`. Si es nulo, se descarta para Q1 y Q3

**3. Manejo de Menciones Vac√≠as:**
- **Hallazgo**: 67.28% de tweets tienen `mentionedUsers` en `null`
- **Soluci√≥n**: Validar `if tweet.get('mentionedUsers') is not None` antes de iterar

**4. Codificaci√≥n de Emojis y Caracteres Especiales:**
- **Hallazgo**: 821 emojis compuestos detectados en muestra + caracteres multiling√ºes (Hindi, Punjabi)
- **Soluci√≥n**: Librer√≠a `emoji` con soporte para `grapheme clusters`. Un emoji compuesto se cuenta como 1 unidad

**5. Normalizaci√≥n de Fechas:**
- **Hallazgo**: Formato ISO 8601 incluye offsets de zona horaria
- **Soluci√≥n**: Extraer solo `.date()` para agrupamiento de Q1

### 4.2. Estrategia de Testing Robustecida

Dada la naturaleza vol√°til de los datos sociales, se implementa una suite de pruebas basada en casos reales detectados:

| Categor√≠a | Caso de Prueba | Entrada Esperada (Mock) | Resultado Esperado | Justificaci√≥n |
| :--- | :--- | :--- | :--- | :--- |
| **Integridad** | JSON Corrupto | `{"date": "2021...", [TRUNCATED]` | Skip / Log error | Evitar ca√≠da del pipeline por truncamiento de archivo. |
| **Q1: Fechas** | Cambio de D√≠a UTC | `2021-02-12T23:59:59+00:00` | Agrupar en `2021-02-12` | Garantizar que el offset no mueva tweets a d√≠as incorrectos. |
| **Q1: Usuarios** | Cambio de Username | `id: 1, user: A` -> `id: 1, user: B` | Conteo √∫nico para `id: 1` | Evitar fragmentaci√≥n de m√©tricas de usuarios activos. |
| **Q2: Emojis** | Secuencias ZWJ | `üë®‚Äçüë©‚Äçüëß‚Äçüë¶` (Familia) | Count = 1 | Evitar sobreconteo de personas individuales en emojis compuestos. |
| **Q2: Emojis** | Modificadores Tono | `üôèüèª` (Manos + Tono) | Count = 1 | Tratar variaciones de tono como una sola unidad visual. |
| **Q3: Menciones** | Menci√≥n Hidden | `.@user` (no al inicio) | Detectar `@user` | Validar que el parser captura menciones en cualquier posici√≥n. |
| **Q3: Menciones** | Metadata vs Regex | `RT @user` | Usar metadata, no Regex | Evitar falsos positivos de texto que no son usuarios v√°lidos. |
| **Rendimiento** | Archivo Vac√≠o | (Archivo de 0 bytes) | `[]` (Empty List) | Manejo elegante de fuentes de datos sin registros. |
| **Consistencia** | Paridad Funcional | Dataset de 1,000 registros | `time == memory` | Garantizar que ambas optimizaciones devuelven el mismo Top 10. |

### 4.3. Herramientas de Calidad
- **`pytest`**: Ejecuci√≥n de la matriz de pruebas anterior.
- **`Ruff`**: Garantiza que el c√≥digo sigue est√°ndares de la comunidad (PEP8) y est√° libre de *dead code*.
- **`detect-secrets`**: Escaneo preventivo para asegurar que no se filtren credenciales de la API de Twitter en los scripts.

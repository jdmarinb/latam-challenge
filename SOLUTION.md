# Data Engineer Challenge Solution

Como el reto no tiene mucho c√≥digo, todo se documenta aqu√≠ en un solo archivo para facilitar la lectura. Para mejorar la redacci√≥n y evitar la redundancia se hace uso de IA para mejora rla docuemntaci√≥n.

## 1. Ambiente de Desarrollo

El reto pide buenas pr√°cticas de git. Para eso, lo primero es que cualquiera pueda configurar el ambiente f√°cil:

```bash
make setup
```

### 1.1. Automatizaci√≥n (`Makefile`)
Centraliza los comandos del proyecto (`setup`, `lint`, `test`, `clean`) para que todos hagan lo mismo de la misma forma. Es robusto, agn√≥stico al lenguaje y est√° en casi todos los sistemas. En Windows se instala con `scoop install make` o revisando la [documentaci√≥n oficial](https://www.gnu.org/software/make/).

### 1.2. Entorno Virtual (`uv`)
Maneja ambientes de Python y paquetes. Se usa por su buen rendimiento y porque genera archivos de `lock` y gestiona `.toml` bien en proyectos complejos.

### 1.3. Dependencias
- `requirements.txt`: paquetes del proyecto
- `requirements-dev.txt`: dependencias de desarrollo (linters, testing) + invoca `requirements.txt` para que el ambiente de desarrollo sea un superconjunto del de producci√≥n

### 1.4. Git Hooks (`pre-commit`)
Automatiza revisi√≥n y formateo *antes* del commit. El c√≥digo que llega al repo cumple los est√°ndares.

**Herramientas:**
- `Ruff`: linter y formateador que detecta errores y code smells
- `detect-secrets`: previene que API keys, passwords, etc. se suban al repo

### 1.5. Commits Convencionales (`Commitizen`)
Fuerza formato est√°ndar en los commits. Mejora la legibilidad del historial, facilita changelogs y permite automatizar versiones.

```bash
make commit  # en lugar de git commit
```

### 1.6. Flujo Git (GitFlow simplificado)
- `main`: versi√≥n estable de producci√≥n
- `develop`: rama principal donde se integra todo
- `feature/<nombre>`: ramas para nuevas funcionalidades, creadas desde `develop`

Mantiene historial limpio y facilita tanto desarrollo como mantenimiento.

## 2. Exploraci√≥n de Datos

Archivo: `farmers-protest-tweets-2021-2-4.json`

### 2.1. Estructura
- **Formato**: JSONL (cada l√≠nea es un JSON independiente)
- **Volumen**: 117,407 registros (~400MB+)
- **Campos clave**:
  - `date`: timestamp del tweet ‚Üí **Q1**
  - `content`: texto con emojis ‚Üí **Q2**
  - `user.username`: usuario que tweetea ‚Üí **Q1**
  - `mentionedUsers`: lista de usuarios mencionados ‚Üí **Q3**

### 2.2. Identificadores
- `id`: num√©rico de 64 bits, identifica cada tweet √∫nico
- `url`: tambi√©n sirve como identificador √∫nico
- **Usuario**: Tiene `user.id` (inmutable) y `user.username` (puede cambiar seg√∫n documentaci√≥n de Twitter). Un usuario puede aparecer m√∫ltiples veces (varios tweets)
- **Importante para Q1**: Se agrupa internamente por `user.id` para evitar fragmentar m√©tricas si alguien cambi√≥ su nombre durante el periodo. Aunque el reto pide devolver `username` (string), primero se cuenta por ID y luego se mapea al username m√°s reciente

### 2.3. Variables necesarias para el an√°lisis

Teniendo en cuenta que cada pregunta requiere un tipo de an√°lisis diferente:

**Q1.** Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as.
```python
[(datetime.date(1999, 11, 15), "LATAM321"), (datetime.date(1999, 7, 15), "LATAM_CHI"), ...]‚Äã
```

**Q2.** Los top 10 emojis m√°s usados con su respectivo conteo.
```python
[("‚úàÔ∏è", 6856), ("‚ù§Ô∏è", 5876), ...]
```

**Q3.** El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos.
```python
[("LATAM321", 387), ("LATAM_CHI", 129), ...]
```

Variables necesarias para responder cada pregunta:

| Pregunta | Variable | Uso |
| :--- | :--- | :--- |
| **Q1** | `date` | Agrupaci√≥n cronol√≥gica por d√≠a. |
| **Q1** | `user.id` | Identificaci√≥n del autor para el conteo por d√≠a (inmutable). |
| **Q1** | `user.username` | Mapeo final para devolver el string solicitado. |
| **Q2** | `content` | Extracci√≥n de emojis del texto. |
| **Q3** | `mentionedUsers` | Lista de usuarios mencionados. |
| **Q3** | `mentionedUsers.username` | Identificaci√≥n del usuario mencionado para el conteo hist√≥rico. |

### 2.4. Errores y Casos Borde

La explicaci√≥n del objeto tweet est√° en la [documentaci√≥n oficial de Twitter](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object). Complementando con investigaci√≥n usando IA (Gemini), se identifican casos de negocio comunes:

**A. El problema de la "Doble Identidad" (Q1)**

La documentaci√≥n de Twitter indica que un usuario puede cambiar su `username` (handle), pero su `id` es inmutable. Si un usuario cambi√≥ su nombre durante el periodo del dataset, contarlo por `username` podr√≠a fragmentar sus m√©tricas.

**Decisi√≥n**: Aunque el reto pide devolver el `username`, internamente se agrupa por `id` y luego se mapea al `username` m√°s reciente.

**B. El campo `mentionedUsers` vs. @texto (Q3)**

El reto pide menciones basadas en el conteo de `@`. Sin embargo, el campo `mentionedUsers` es un objeto enriquecido por Twitter que ya parse√≥ el texto.

**Caso Borde**: ¬øQu√© pasa si el texto dice `@usuario` pero el objeto `mentionedUsers` es `null` (com√∫n en tweets borrados o para cuentas suspendidas)?

**Decisi√≥n**: Se usa el campo estructurado `mentionedUsers` (m√°s eficiente y captura menciones "invisibles" como hidden/reply) en lugar de regex sobre el texto. Si es `null`, el tweet no cuenta menciones aunque el texto tenga `@`.

**C. La trampa de los Emojis Compuestos (Q2)**

Los ZWJ (Zero Width Joiners) unen m√∫ltiples emojis. Ejemplo: el emoji de "Familia" üë®‚Äçüë©‚Äçüëß‚Äçüë¶ es en realidad 4 emojis unidos por caracteres invisibles.

**Decisi√≥n**: Se usa `emoji.analyze()` con soporte para secuencias ZWJ completas. De lo contrario, el top 10 se llenar√° de "hombres", "mujeres" y "ni√±os" individuales en lugar de "familia".

**D. Q1: El desaf√≠o del "Usuario con m√°s tweets por d√≠a"**

Esta pregunta es un Top-N de un Top-N:
1. Encontrar los Top 10 d√≠as con m√°s tweets
2. Para cada uno de esos 10 d√≠as, encontrar el usuario m√°s activo

**Decisi√≥n**: Optimizaci√≥n en 2 pasos para no guardar diccionario gigante `{fecha: {usuario: cuenta}}`:
- Paso 1: Contar tweets por fecha y obtener Top 10 fechas
- Paso 2: Solo para esas 10 fechas, acumular conteos de usuarios

**E. La Pesadilla de Unicode (Normalizaci√≥n NFKC)**

En Q1 (usernames) y Q2 (emojis), Python puede traicionar si no se normaliza Unicode.

**El Problema**: El car√°cter `√±` se puede escribir de dos formas en bytes:
1. Como un solo car√°cter (U+00F1)
2. Como `n` + s√≠mbolo `~` (U+006E + U+0303)

**El Riesgo**: Para Python, `"Pe√±a" != "Pe√±a"`. Si no se normaliza, `collections.Counter` los cuenta como dos usuarios o emojis distintos, fragmentando el Top 10.

**Decisi√≥n**: Aplicar `unicodedata.normalize('NFKC', text)` antes de contar.

**F. Comportamiento de Bots (Outliers en Q1)**

Q1 pide el usuario con m√°s tweets por d√≠a. En eventos como el Farmers Protest hay muchos bots.

**El Riesgo**: Si un usuario tiene 5,000 tweets en un d√≠a (bot haciendo spam), t√©cnicamente es el "Top 1", pero ensucia el an√°lisis.

**Decisi√≥n**: Se reportan tal cual lo pide el enunciado, pero se verifica la distribuci√≥n de tweets por usuario. Si el Top 1 tiene 100x m√°s tweets que el Top 2, se menciona en documentaci√≥n como observaci√≥n de calidad de datos.

**G. Case Sensitivity (Q1 y Q3)**

Twitter trata los usernames como case-insensitive, pero los datos crudos pueden variar.

**El Riesgo**: `@Latam321` y `@latam321` son la misma persona. Si se cuentan strings crudos, se divide su influencia.

**Decisi√≥n**: Convertir siempre a `.lower()` antes de agrupar en Q1 y Q3.

**H. Determinismo en Empates (Sorting)**

**El Problema**: El reto pide "Top 10". ¬øQu√© pasa si el usuario #10 y el #11 tienen exactamente 50 tweets?

**El Riesgo**: El ordenamiento est√°ndar de Python (`sort`) es estable, pero sin criterio de desempate expl√≠cito, el c√≥digo podr√≠a devolver resultados diferentes en ejecuciones distintas en sistemas distribuidos.

**Decisi√≥n**: Implementar criterio de ordenamiento secundario: `sort(key=lambda x: (-count, username))` para garantizar determinismo.

Para analizar estos y otros casos presentes en los datos, se realiza una exploraci√≥n de una muestra en [challenge.ipynb](src/challenge.ipynb).

Tras un an√°lisis estad√≠stico de 10,000 registros, se identificaron los siguientes casos cr√≠ticos:

**An√°lisis Estad√≠stico de Calidad (n=10,000):**
- **Integridad Estructural**: No se detectaron discrepancias de tipos en `date` (100% string) o `content` (100% string)
- **Menciones (Q3)**: El campo `mentionedUsers` es altamente vol√°til. El 67.28% de los tweets son `null` (NoneType), mientras que el 32.72% son listas. No se detectaron listas vac√≠as (`[]`)
- **Complejidad de Texto (Q2)**: Se detectaron 821 emojis complejos (multi-char/compound). Emojis como `üôèüèª` (manos en oraci√≥n con tono de piel) o banderas como `üáÆüá≥` requieren tratamiento de grafemas
- **Extremos de Contenido**: Tweets desde 15 hasta 852 caracteres, implica que el parsing de texto debe ser eficiente
- **Ratio de Repetici√≥n de Usuarios**: 2.20x, justifica el uso de `sys.intern()` para optimizar memoria

**Casos Borde y de Negocio Identificados:**

| Variable | Caso de Prueba / Anomal√≠a | Frecuencia / Ejemplo | Estrategia de Mitigaci√≥n |
| :--- | :--- | :--- | :--- |
| `date` | Desfase de Zona Horaria | `2021-02-21T23:39:32+00:00` | Normalizaci√≥n mandatoria a UTC `.date()` para evitar saltos de d√≠a. |
| `content` | Emojis con ZWJ (Zero Width Joiners) | `üë®‚Äçüë©‚Äçüëß‚Äçüë¶` = 4 emojis unidos | Uso de `emoji.analyze()` con soporte para secuencias ZWJ completas. |
| `content` | Multiling√ºismo (Hindi/Punjabi) | `.@RakeshTikaitBKU ‡§¨‡•ã‡§≤‡•á- ‡§∏‡§Ç‡§∏‡§¶ ‡§ú‡§æ‡§ï‡§∞...` | El parser debe soportar codificaci√≥n `utf-8` para no corromper texto en otros idiomas. |
| `content` | Truncamiento (Legacy) | Clave `truncated` no existe | El dataset parece pre-procesado (aplanado), pero se valida fin de texto `‚Ä¶`. |
| `mentionedUsers` | Menciones "Invisibles" | Hidden/Reply | Uso de metadata `mentionedUsers` en lugar de Regex para capturar menciones que no est√°n en el texto visible. |
| `mentionedUsers` | Referencia Nula vs @texto | `null` vs `@falso_positivo` | Se prioriza metadata oficial sobre Regex para evitar falsos positivos de texto. |
| `user.username` | Ratio de Repetici√≥n | 2.20x | Justifica el uso de `sys.intern()` para optimizar memoria RAM. |
| `all` | Retweets (Duplicidad) | `RT @...` (0.05% muestra) | Interpretaci√≥n estricta: se cuentan los emojis/menciones de RTs como publicaciones nuevas. |

**Conclusiones:**
- El archivo es grande (~400MB+). Leerlo completo en memoria (`json.load`) puede causar problemas en recursos limitados
- **Recomendaci√≥n**: procesamiento por streaming (l√≠nea por l√≠nea) para optimizar memoria
- La estructura anidada (`user`, `mentionedUsers`) requiere navegaci√≥n cuidadosa del JSON para evitar errores por campos nulos

## 3. Estrategias de Optimizaci√≥n

Una de las estrategias centrales es aprovechar capacidades nativas y librer√≠as optimizadas para maximizar la eficiencia en ambos frentes:

- **String Interning (`sys.intern`)**:
  - **Memoria**: Basado en un **ratio de repetici√≥n de 2.20x**, esta t√©cnica fuerza a Python a reutilizar el mismo objeto en RAM para valores id√©nticos. Reduce el *footprint* al evitar duplicados de texto denso en los diccionarios de Q1 y Q3.
  - **Tiempo**: Acelera los agrupamientos y b√∫squedas, ya que las comparaciones entre strings "internados" se realizan por direcci√≥n de memoria (punteros) en lugar de evaluar car√°cter por car√°cter.

- **Normalizaci√≥n On-the-fly**:
  - **Memoria**: Al aplicar Unicode NFKC y conversi√≥n a min√∫sculas *durante* la lectura, evitamos duplicar estructuras de datos (versi√≥n original vs procesada).
  - **Tiempo**: Implementa un patr√≥n de **Single Pass** (pasada √∫nica), eliminando la latencia de recorrer el dataset m√∫ltiples veces para limpieza y agregaci√≥n.


### 3.1. Optimizaci√≥n de Tiempo (Latencia)

**`polars`:** Al representar un archivo `Json` de manera columnar atravez de Apache Arrow lo que permite hacer **Projection Pushdown** y **Predicate Pushdown** automaticamente; en su modo Lazy. Por lo que sera una opci√≥n a considerar principalmente en la optimizaci√≥n de tiempo. Al ser **Multi-thread** divide el archivo en __"Chunks"__ de tama√±o √≥ptimo para maximizar el uso de los hilos del CPU sin saturar la comunicaci√≥n. Adicionalmente al ser **Single Node** (los hilos intercambian datos en la RAM) y no distribuido como Spark (los nodos intercambian dato spor la RED), el shuffle no es tan costoso, lo qeu lo hace ideal para este caso en que mos archivos noestan particionados (JSON). Adicionalmente al estar programado en `rust` es multihilo loq eu lo hace m√°s eficiente para procesamiento en paralelo que usar `ProcessPoolExecutor`. Adicionalmente s epeude aprovechar la vectoricaci√≥n + SIMD nativa del paquete, pese a no ser ser el mejor escenario (operaciones n√∫mericas), agrega eficiencia por ejemplo al realizar funciones de agregaci√≥n. Adem√°s de esto como cualquier motor de procesamiento por columnas se ve beneficiado cuando se le indica el esquema de las varaibles en lugar de dejar que este las infiera.

### 3.2. Optimizaci√≥n de Memoria (Footprint)

**`orjson`:** Es un motor de parsing y serializaci√≥n JSON de alto rendimiento implementado en Rust. Supera al m√≥dulo est√°ndar de Python al procesar directamente estructuras de bytes y datetime, eliminando el overhead de decodificaci√≥n y transformaci√≥n de tipos. Reduce significativamente la latencia de CPU en la deserializaci√≥n y habilita un patr√≥n de lectura en streaming (procesamiento secuencial). Al usar algoritmos **Single Pass** permite iterar sobre grandes vol√∫menes de datos manteniendo una huella de memoria (memory footprint) constante y m√≠nima, independientemente del tama√±o total del archivo. Combinado con programaci√≥n funcional  **`itertools`** **`collections.Counter`**  Evita crear listas intermedias de objetos. `Counter` es un `dict` optimizado en C.


### 3.3. Decisiones de Dise√±o por Pregunta

| Pregunta | Estrategia T√©cnica | Justificaci√≥n Basada en Exploraci√≥n |
| :--- | :--- | :--- |
| **Q1** | Agrupaci√≥n H√≠brida (ID + Map) | Evita fragmentaci√≥n por cambio de usernames; garantiza integridad del conteo hist√≥rico. |
| **Q2** | An√°lisis de Grafemas (ZWJ) librer√≠a **`emoji`** | Detectado en exploraci√≥n (1,188 emojis complejos); garantiza que `üë®‚Äçüë©‚Äçüëß‚Äçüë¶` no se cuente como 4 personas. |
| **Q3** | Metadata-First (No Regex) | Evita 15% de falsos positivos y captura 14% de menciones "invisibles" (replies/metadata). |

**Nota:** En la pregunta 2 se utiliza la librer√≠a **`emoji`**, aportando la garant√≠a t√©cnica para manejar secuencias ZWJ (Zero Width Joiners) y modificadores de tono de piel. Sin ella, los conteos de Q2 ser√≠an err√≥neos al fragmentar grafemas. Adem√°s sustituye el uso de expresiones regulares (Regex) masivas por algoritmos de b√∫squeda optimizados, reduciendo el costo de CPU asociado al *backtracking* de patrones complejos.

## 4. Benchmarks


Para medir el rendimiento del algoritmo en tiempo y memoria se utilizan las librerias `memory_profiler` y `cProfile` y `pstats` para medir los tiempos como se sugeria en el  [README.md](README.md). Haciendo uso de esta misma funci√≥n optimiz√≥ cada parte del codigo.

### 4.1 Lectura de Archivo
Lo primero a optimizar es la lectura de los datos, comparando todas las metodolog√≠as de ingesta evaluadas para el dataset de 400MB.

| M√©todo | Tiempo Real (s) | RAM Pico (MB) | Retorno | Veredicto |
| :--- | :--- | :--- | :--- | :--- |
| **Polars Lazy + Schema** | **~0.00** | **~3138** | LazyFrame | **1¬∞ Tiempo 1¬∞ Memoria**. (Lazy). |
| **Streaming/Chunks Orjson** | **~0.00** | **~3776** | Generador | **1¬∞ Tiempo 2¬∞ Memoria** (Lazy). |
| **Polars Eager + Schema** | **~0.33** | **~4761** | DataFrame | Bueno. (Materialized)|
| **Polars Lazy (Scan)** | ~0.40 | ~4763 | LazyFrame | Bueno (Inferencia). |
| **Polars Eager (Read)** | ~6.65 | ~5121 | DataFrame | Lento (Inferencia). |
| **Standard JSON** | ~9.90 | ~4500 | Lista | Lento (Materialized). |
| **Pandas read_json** | ~10.41 | ~5492 | DataFrame | **Inadecuado** (OOM Risk). |
| **Full Memory** | ~11.06 | ~4257 | Lista | Ineficiente (Redundancia). |

*\*Polars requiere esquemas fijos (`pl.Struct`) para evitar errores de inferencia.*

**Nota sobre Polars**: Debido a que la versi√≥n **Lazy** no materializa los datos de forma inmediata (solo prepara el plan de ejecuci√≥n), el benchmark reporta tiempos de 0.00s. Se identific√≥ que al definir el esquema, Polars Lazy reduce su pico de memoria a **~3.1GB**, siendo el m√©todo m√°s eficiente dentro de la suite de Polars para la gesti√≥n de recursos.

#### An√°lisis Detallado de Rendimiento (Python Profilers)
Tras aplicar `cProfile` y `pstats` en un laboratorio modular, se identificaron los cuellos de botella reales:
- **Overhead de `raw_decode`**: El perfilado de `Standard JSON` revel√≥ que el ~60% del tiempo acumulado (~6.3s de 10.3s totales del profiler) se consume en la funci√≥n interna de decodificaci√≥n de strings, justificando el paso a motores de Rust/C como `orjson`.
- **Overhead de Instrumentaci√≥n**: Se confirm√≥ que el uso de profilers a√±ade un retraso artificial (ej. de 9.9s real a 11.8s en ejecuci√≥n profilada), por lo que las m√©tricas finales se basan en mediciones de tiempo "Wall-clock" desacopladas.


### 4.2. Procesamiento

Para el procesamiento se evaluan las opciones de lectura elegdas **`polars`** con schema en sus versiones **Lazy** y **Eager** y el procesamiento en formato vectorial, y por otro lado **`orJson`** con procesamiento en el paradigma **funcional**. Ambos metodos en *streamig* y en *batch*. **String Interning** y **Normalizaci√≥n On-the-fly**. Adem√°s de las optimizaciones especificas para cada caso definidas ene el punto **3.3.**.

Debido a la latencia extra generada por archivos.ipynb se realiza la comparaci√≥n d eestos m√©todos en el archivo [benchmark.py](benchmark.py). Para realizar esta prueba se definen algunas funciones decorador para evaluar las diferentes combinaciones de lectores y procesamiento, de modo qeu efectivamente se peuda elegir la mejor opci√≥n en cada

#### 4.2.1. Pregunta 1: Top 10 Fechas y Usuarios m√°s activos

En esta pregunta, el cuello de botella es la agregaci√≥n doble (por fecha y luego por usuario).

| M√©todo | Tiempo (s) | RAM (MB) | Veredicto |
| :--- | :---: | :---: | :--- |
| **Polars Lazy** | **0.20** | 624.50 | **1¬∞ Tiempo**. Agregaci√≥n vectorial eficiente. |
| **Polars Streaming** | 0.21 | 565.72 | Excelente balance. |
| **ORJSON Streaming** | 2.59 | **113.57** | **1¬∞ Memoria**. Ideal para recursos limitados. |
| ORJSON + Threading | 2.82 | 164.48 | Similar a streaming, ligero overhead. |
| ORJSON + Processing | 5.54 | 542.75 | Ineficiente para esta carga simple. |

**Conclusi√≥n**: **Polars** domina en latencia por su capacidad de realizar agregaciones en paralelo sobre memoria contigua. **ORJSON Streaming** es la mejor opci√≥n si la restricci√≥n es el *footprint* de RAM.

#### 4.2.2. Pregunta 2: Top 10 Emojis m√°s usados

Esta es la tarea m√°s intensiva en CPU. Se evaluaron tres enfoques: Precisi√≥n total con librer√≠a, Regex simple para velocidad y Regex (ZWJ Support) para un balance √≥ptimo.

| Enfoque | M√©todo | Tiempo (s) | RAM (MB) | Veredicto |
| :--- | :--- | :---: | :---: | :--- |
| **Precisi√≥n** | **ORJSON + Multyprocessing (`emoji`)** | **7.90** | 797.96 | **1¬∞ Tiempo Preciso**. Evade el GIL. |
| | Polars Lazy (`emoji`) | 22.62 | 597.86 | Lento (Serializado por map_elements). |
| | Polars Streaming (`emoji`) | 22.70 | 659.02 | Lento. |
| | Polars Eager (`emoji`) | 22.60 | 714.15 | Lento. |
| | **ORJSON Streaming (`emoji`)** | 25.38 | **367.57** | **1¬∞ Memoria Precisa**. |
| | ORJSON + Threading (`emoji`) | 24.91 | 416.00 | GIL bloquea beneficio de hilos. |
| **Eficiencia** | **Polars Streaming (Regex)** | **0.34** | 594.46 | **Ganador Absoluto en Tiempo**. |
| | Polars Lazy (Regex) | 0.42 | 494.61 | Muy eficiente. |
| | Polars Eager (Regex) | 0.47 | 723.76 | Mayor consumo RAM. |
| | **ORJSON Streaming (Regex)** | 3.65 | **110.92** | **Ganador Absoluto en Memoria**. |
| | ORJSON + Threading (Regex) | 3.79 | 161.54 | Ligero overhead. |
| | ORJSON + Processing (Regex) | 6.69 | 550.05 | IPC costoso para Regex r√°pida. |
| **Balanceado** | **Polars Streaming (ZWJ Support)** | **0.35** | 633.68 | **RECOMENDADO**. ZWJ + Velocidad Rust. |
| | Polars Lazy (ZWJ Support) | 0.46 | 597.33 | Muy eficiente. |
| | **ORJSON Streaming (ZWJ Support)** | 4.06 | **110.84** | **1¬∞ Memoria (ZWJ Support)**. |
| | ORJSON + Threading (ZWJ Support) | 4.27 | 163.49 | Similar a streaming. |
| | ORJSON + Processing (ZWJ Support) | 7.21 | 540.87 | Paralelismo de CPU efectivo. |

**Conclusi√≥n**:
1. **Precisi√≥n vs Velocidad**: El uso de la librer√≠a `emoji` garantiza el conteo exacto de grafemas complejos pero es ~70 veces m√°s lento que una **Regex (ZWJ Support)** vectorizada en Polars (~25s vs ~0.35s).
2. **Impacto del GIL**: El an√°lisis de emojis es una tarea CPU-bound. En el nivel de m√°xima precisi√≥n, el **Multiprocessing** reduce el tiempo en un 70% al evadir el GIL de Python.
3. **Optimizaci√≥n Vectorial**: La **Regex (ZWJ Support)** en Polars representa el punto de equilibrio ideal: mantiene la capacidad de reconocer secuencias ZWJ con el rendimiento nativo de Rust. **ORJSON Streaming (Robust Regex)** es la opci√≥n ganadora si se requiere soporte ZWJ con una huella de memoria m√≠nima (~110MB).

Teniendo en cuenta que Latam es una empresa de tranporte de vuelos muy probablemente el gruso de los emojis qeu hacen referencia a esta y que necesita analizar se da con emojis comunes como y no se requiere un nivel de presici√≥n tan grande adem√°s al ser peque√±a la difenrecia enetre usar **regex** y **regex con ZWJ support**, se decide hacer uso de estas ultimas. Pese a qeu previamente se hab√≠a mencionado la preferencia por usar la librer√≠a emoji.

#### 4.2.3. Pregunta 3: Top 10 Usuarios Influyentes (Menciones)

El procesamiento de metadatos (`mentionedUsers`) es r√°pido, similar a Q1.

| M√©todo | Tiempo (s) | RAM (MB) | Veredicto |
| :--- | :---: | :---: | :--- |
| **Polars Lazy** | **0.31** | 664.85 | **1¬∞ Tiempo**. `explode` de listas es muy r√°pido en Polars. |
| Polars Eager | 0.32 | 735.61 | Rendimiento equivalente a Lazy. |
| **ORJSON Streaming** | 2.65 | **379.57** | **1¬∞ Memoria**. Huella de memoria muy optimizada. |
| ORJSON + Processing | 6.46 | 806.20 | El costo de IPC (comunicaci√≥n entre procesos) supera el beneficio. |

**Conclusi√≥n**: **Polars** es la opci√≥n preferida para anal√≠tica r√°pida de metadatos estructurados. **ORJSON Streaming** sigue siendo el l√≠der en eficiencia de memoria para procesar el dataset completo.

**Nota:** Todos los benchmarks realizados se encuentran el el archivo [challenge.ipynb](solucion/challenge.ipynb), para su revisi√≥n y los benchmarks principales se programaron ene el archivo y los resultado en el archivo [benchmark_results.txt](solucion/benchmark_results.txt).

### 4.3. Resultados Finales de Benchmarking

Tras la implementaci√≥n del **Canonical Logger (Wide Events)** y el perfilado exhaustivo con `cProfile`, se obtuvieron los siguientes resultados finales para el dataset completo (~400MB):

| Funci√≥n | Tiempo Real (s) | Memoria Pico (MB) | Cuello de Botella (cProfile) | Latencia Cr√≠tica (Pasos del Log) |
| :--- | :---: | :---: | :--- | :--- |
| **Q1 Time** | 0.4752 | 516.50 | `pl.LazyFrame.collect` | `execution_collect`: 471.78ms |
| **Q1 Memory** | 9.0248 | 187.09 | `reduce` + `orjson.loads` | `count_users`: 4635.82ms |
| **Q2 Time** | 0.4323 | 517.61 | `str.extract_all` (Regex) | `execution_collect`: 430.58ms |
| **Q2 Memory** | 4.5875 | 207.40 | `re.findall` | `aggregate_counts`: 4584.47ms |
| **Q3 Time** | 0.4784 | 634.33 | `explode` + `collect` | `execution_collect`: 477.15ms |
| **Q3 Memory** | 3.8086 | 310.55 | `orjson.loads` | `aggregate_counts`: 3758.52ms |

**Observaciones clave de observabilidad:**
- El **Canonical Logger** permiti√≥ identificar que el 99% del tiempo en las versiones `Time` se consume en la etapa de materializaci√≥n (`collect`), mientras que en las versiones `Memory` el costo principal reside en la deserializaci√≥n de JSON l√≠nea a l√≠nea.
- El overhead del logger Wide Event es despreciable (microsegundos), aportando una trazabilidad total por cada unidad de trabajo.

## 5. Calidad de Software

### 5.1. Manejo de Errores

Basado en el an√°lisis del dataset, se implementan las siguientes estrategias:

**1. Resiliencia al Parsing (JSONL Corruption):**
- **Riesgo**: L√≠neas truncadas o caracteres de escape mal procesados en archivo de 400MB+
- **Soluci√≥n**: Bloque `try-except` alrededor de `orjson.loads()`/`ujson.loads()`. Las l√≠neas corruptas se registran en log pero no detienen la ejecuci√≥n

**2. Esquema de Usuario Inconsistente:**
- **Riesgo**: El objeto `user` es anidado y campos podr√≠an ser nulos
- **Soluci√≥n**: Acceso seguro `tweet.get('user', {}).get('username')`. Si es nulo, se descarta para Q1 y Q3

**3. Manejo de Menciones Vac√≠as:**
- **Hallazgo**: 67.28% de tweets tienen `mentionedUsers` en `null`
- **Soluci√≥n**: Validar `if tweet.get('mentionedUsers') is not None` antes de iterar

**4. Codificaci√≥n de Emojis y Caracteres Especiales:**
- **Hallazgo**: 821 emojis compuestos detectados en muestra + caracteres multiling√ºes (Hindi, Punjabi)
- **Soluci√≥n**: Librer√≠a `emoji` con soporte para `grapheme clusters`. Un emoji compuesto se cuenta como 1 unidad

**5. Normalizaci√≥n de Fechas:**
- **Hallazgo**: Formato ISO 8601 incluye offsets de zona horaria
- **Soluci√≥n**: Extraer solo `.date()` para agrupamiento de Q1

### 5.2. Estrategia de Testing Robustecida

Dada la naturaleza vol√°til de los datos sociales, se implementa una suite de pruebas basada en casos reales detectados:

| Categor√≠a | Caso de Prueba | Entrada Esperada (Mock) | Resultado Esperado | Justificaci√≥n |
| :--- | :--- | :--- | :--- | :--- |
| **Integridad** | JSON Corrupto | `{"date": "2021...", [TRUNCATED]` | Skip / Log error | Evitar ca√≠da del pipeline por truncamiento de archivo. |
| **Q1: Fechas** | Cambio de D√≠a UTC | `2021-02-12T23:59:59+00:00` | Agrupar en `2021-02-12` | Garantizar que el offset no mueva tweets a d√≠as incorrectos. |
| **Q1: Usuarios** | Cambio de Username | `id: 1, user: A` -> `id: 1, user: B` | Conteo √∫nico para `id: 1` | Evitar fragmentaci√≥n de m√©tricas de usuarios activos. |
| **Q2: Emojis** | Secuencias ZWJ | `üë®‚Äçüë©‚Äçüëß‚Äçüë¶` (Familia) | Count = 1 | Evitar sobreconteo de personas individuales en emojis compuestos. |
| **Q2: Emojis** | Modificadores Tono | `üôèüèª` (Manos + Tono) | Count = 1 | Tratar variaciones de tono como una sola unidad visual. |
| **Q3: Menciones** | Menci√≥n Hidden | `.@user` (no al inicio) | Detectar `@user` | Validar que el parser captura menciones en cualquier posici√≥n. |
| **Q3: Menciones** | Metadata vs Regex | `RT @user` | Usar metadata, no Regex | Evitar falsos positivos de texto que no son usuarios v√°lidos. |
| **Rendimiento** | Archivo Vac√≠o | (Archivo de 0 bytes) | `[]` (Empty List) | Manejo elegante de fuentes de datos sin registros. |
| **Consistencia** | Paridad Funcional | Dataset de 1,000 registros | `time == memory` | Garantizar que ambas optimizaciones devuelven el mismo Top 10. |

### 5.3. Herramientas de Calidad
- **`pytest`**: Ejecuci√≥n de la matriz de pruebas anterior.
- **`Ruff`**: Garantiza que el c√≥digo sigue est√°ndares de la comunidad (PEP8) y est√° libre de *dead code*.
- **`detect-secrets`**: Escaneo preventivo para asegurar que no se filtren credenciales de la API de Twitter en los scripts.

### 5.4. Implementaci√≥n
Apoyado en el analisis realizado en el punto **2.4.** y siguiendo las estrategias de los puntos **5.1.**, **5.2.** y **5.3.**. Se desarrollan los test unitarios con apoyo de un agente de programaci√≥n.

### 5.5 Obserbabilidad
Se usa una estrategia de loggin basado en Cannonical logger (Wide Events), con ayuda de la IA se implementa un logger con **`structlog`**  para monitorear el comportamiento del sistema en producci√≥n. Los logs se guardan en `logs/app.log` y se configuran para registrar:
- **Errores cr√≠ticos** (corrupci√≥n de datos, fallos de lectura)
- **Eventos de auditor√≠a** (tweets procesados, m√©tricas calculadas)
- **M√©tricas de rendimiento** (tiempos de procesamiento por paso)


## 6. Despliegue en la nube

El paso final es la integraci√≥n en un entorno de GCP, para esto supondremos que el proceso sera el siguiente


```mermaid
graph LR
    A[GCS Bucket: Input] -->|Event: Finalize| B[Pub/Sub Topic]
    B --> C[Cloud Function]
    C -->|Q1 Result| D[GCS Bucket: Output / Avro]
    E[HTTP Request] --> C
    C -->|Q2/Q3 Result| F[HTTP JSON Response]
```

**Flujo de Trabajo:**
1. **Ingesta**: Un archivo JSONL se carga en el bucket de entrada.
2. **Orquestaci√≥n**: GCS dispara una notificaci√≥n a un t√≥pico de **Pub/Sub**.
3. **Procesamiento**: Una **Cloud Function** (usando el c√≥digo optimizado de Polars/Orjson) procesa el archivo.
   - Si es disparada por evento (Batch): Ejecuta **Q1** y guarda el resultado en formato **Avro** para persistencia eficiente.
   - Si es llamada v√≠a HTTP (On-demand): Ejecuta **Q2/Q3** y retorna una repuesta HTTP (JSON).
4. **Monitoreo**: Logs estructurados se integran autom√°ticamente con **Cloud Logging**.

**Nota:** Es encesario qeu la cloud function sea de segunda generaci√≥n para que admita tanto http como pub-sub.

### 6.3. Configuraci√≥n y Despliegue

Para que el despliegue autom√°tico funcione correctamente, se deben configurar las siguientes variables y secretos en el repositorio de GitHub:

| Nombre | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `GCP_SA_KEY` | **Secret** | JSON Key completo (crudo) de la Service Account. |
| `GCP_PROJECT_ID` | **Variable** | ID √∫nico del proyecto en Google Cloud Platform. |
| `GCP_REGION` | **Variable** | Regi√≥n de despliegue (ej: `us-central1`). |

*Nota: La variable `INPUT_FILE_PATH` es gestionada autom√°ticamente por Terraform bajo el esquema `gs://{bucket}/input/`.*

#### Permisos de IAM Requeridos

Para un despliegue exitoso, la Service Account de GitHub Actions debe tener los siguientes roles:
1. **`roles/storage.admin`**: Gesti√≥n de buckets y artefactos de c√≥digo.
2. **`roles/pubsub.admin`**: Creaci√≥n de t√≥picos para notificaciones.
3. **`roles/cloudfunctions.developer`**: Despliegue de la l√≥gica serverless.
4. **`roles/iam.serviceAccountUser`**: Permiso para asignar la cuenta de servicio a la funci√≥n.
5. **`roles/resourcemanager.projectIamAdmin`**: (Opcional) si Terraform debe gestionar permisos de IAM.

La cuenta de ejecuci√≥n (**Runtime**) de la funci√≥n solo requiere:
- **`roles/storage.objectViewer`** (Lectura de Input).
- **`roles/storage.logging.logWriter`** (Escritura de Logs).

#### Configuraci√≥n de Identidad (GCP Shell)

Para habilitar el despliegue autom√°tico, ejecute estos comandos una √∫nica vez para crear la identidad que usar√° GitHub Actions:

```bash
# Definir variables
export PROJECT_ID="latam-challenge-485101"
export SA_NAME="github-deployer"

# 1. Crear Service Account
gcloud iam service-accounts create $SA_NAME --display-name="GitHub Deployer"

# 2. Asignar Permisos Administrativos a la SA
# Nota: Se recomiendan roles Admin para que Terraform gestione pol√≠ticas de IAM (Cloud Run/Eventarc) sin conflictos.
for ROLE in storage.admin pubsub.admin cloudfunctions.admin run.admin resourcemanager.projectIamAdmin iam.serviceAccountUser; do
  gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member="serviceAccount:$SA_NAME@$PROJECT_ID.iam.gserviceaccount.com" \
    --role="roles/$ROLE"
done

# 3. Generar Llave JSON (Copiar contenido en secreto GCP_SA_KEY de GitHub)
gcloud iam service-accounts keys create github-key.json \
  --iam-account=$SA_NAME@$PROJECT_ID.iam.gserviceaccount.com
```

*Nota: La habilitaci√≥n de APIs y los permisos internos de infraestructura (Eventarc/Storage) son gestionados autom√°ticamente por Terraform.*

Pasos:
1. Configurar una cuenta de servicio como variable de entorno en el repositorio de github
2. Acondicionar el codigo
  - Hacer que la funciones de lectura puedan leer desde GCS
  - Crear una funci√≥n apra escribir el resultado tambien en GCS
  - Crear el archivo main.py (functions framework), qeu permita recibir los parametros por http y llamar a las funciones correspondientes
3. desarrollar la IasC con Terraform en un carpeta terraform
   - Bucket de
   - Cloud Function
   - Pub/Sub
   - almacenamiento de logs en GCP
4. Crear un workflow de github actions que haga el deploy
5. Probar el sistema con un archivo de prueba usando el archivo de la prueba

#### Escalamiento en Big-data

Si los datos escalaran a billones de registros, se aplicar√≠an estrategias adicionales que requieren infraestructura y cambio de tecnologias, probablemente spark o flink:

**5. Estrategia de Manejo de Errores y Calidad de Datos (Pr√≥ximos Pasos):**
- **Reporte de Integridad en Log**: En lugar de simplemente omitir registros corruptos, el sistema podr√≠a acumular contadores vectoriales (ej: `null_user_ids`, `invalid_usernames`) y emitirlos en el **Wide Event**.
- **DLQ (Dead Letter Queue)**: Para registros que fallen el parsing estructural, se implementar√≠a una ruta de salida secundaria que almacene el JSON crudo junto con el motivo del fallo (`tweet_id`, `reason`), permitiendo auditor√≠as de calidad de datos sin degradar el rendimiento del pipeline principal.
- **Validaci√≥n de Esquema Estricta**: Integrar validadores como Pydantic o esquemas de Apache Arrow m√°s restrictivos para detectar derivas en la estructura de los datos de Twitter (Data Drift).

**1. Formato Columnar (Parquet/Avro):**
- Permite leer solo columnas necesarias (ej: solo `date` y `user`)
- Compresi√≥n de strings repetitivos (usernames)
- Reduce dr√°sticamente I/O y memoria

**2. Particionamiento:**
- Particionar f√≠sicamente por `year/month/day`
- El motor ignora carpetas que no coinciden con el rango consultado

**3. Probabilistic Data Structures:**
- **HyperLogLog**: conteos de cardinalidad (Q3) con error m√≠nimo
- **Count-Min Sketch**: frecuencias de top-k (Q2)
- Memoria fija (KB en lugar de GB)

**4. Pre-agregaci√≥n:**
- ETL que genere agregados horarios/diarios
- Consultas de "Top 10" instant√°neas al leer pre-calculados

## 6. Ejecuci√≥n y Conclusiones Finales

### 6.1. Gu√≠a de Inicio R√°pido

Para validar la soluci√≥n y los benchmarks presentados, ejecute los siguientes comandos en orden:

```bash
# 1. Configurar el entorno (Instala uv, crea venv, instala dependencias)
make setup

# 2. Ejecutar los tests (Verifica la l√≥gica de las 6 funciones)
make test

# 3. Ejecutar Benchmarks (Genera el reporte de performance)
python solution/benchmark.py
```

Una vez desplegada la infraestructura, siga estos pasos para validar el flujo completo de datos.

### 6.2. Carga de Datos (Disparador Batch)

Suba el dataset a la carpeta `input/` del bucket creado. Esto disparar√° autom√°ticamente la Cloud Function a trav√©s de Pub/Sub para procesar la **Q1**.

```bash
# Definir variables de prueba
export BUCKET_NAME="latam-challenge-485101-lake"
export FILE_NAME="farmers-protest-tweets-2021-2-4.json"

# Subir archivo al bucket usando gcloud storage
gcloud storage cp $FILE_NAME gs://$BUCKET_NAME/input/
```

### 6.3. Verificaci√≥n de Procesamiento (Pub/Sub)

Para confirmar que el evento fue capturado y procesado, consulte los logs estructurados:

```bash
# Consultar logs de la √∫ltima ejecuci√≥n
gcloud alpha logging read "resource.type=cloud_function AND resource.labels.function_name=tweet-processor" --limit=10 --format="json"
```

### 6.4. Consulta On-demand (HTTPS)

Solicite los resultados de las preguntas **Q2** o **Q3** bajo demanda utilizando el archivo ya presente en el bucket.

```bash
# Ejemplo: Obtener Top 10 Emojis (Q2) con estrategia de Memoria
curl "https://us-central1-latam-challenge-485101.cloudfunctions.net/tweet-processor?q=q2&strategy=memory&file=gs://$BUCKET_NAME/input/$FILE_NAME"

# Ejemplo: Obtener Top 10 Usuarios influyentes (Q3) con estrategia de Tiempo
curl "https://us-central1-latam-challenge-485101.cloudfunctions.net/tweet-processor?q=q3&strategy=time&file=gs://$BUCKET_NAME/input/$FILE_NAME"
```

### Conclusi√≥n

Basado en los resultados obtenidos, esta es la recomendaci√≥n de uso para cada paradigma implementado:

| Criterio | Soluci√≥n Recomendada | Justificaci√≥n T√©cnica |
| :--- | :--- | :--- |
| **Baja Latencia (Real-time)** | `qX_time` (Polars) | Ideal para dashboards o APIs donde la velocidad es cr√≠tica. Aprovecha el paralelismo nativo de Rust. |
| **Sistemas Legacy / Serverless** | `qX_memory` (Orjson) | Ideal para AWS Lambda o contenedores con poca RAM (512MB o menos). Mantiene un footprint constante. |
| **Procesamiento de Emojis** | `q2_time` (Regex Robust) | El balance perfecto entre velocidad y soporte para grafemas complejos (ZWJ). |

Este reto demuestra que no existe una "bala de plata" en la ingenier√≠a de datos.
- Mientras que **Polars** redujo los tiempos de procesamiento a menos de **0.5 segundos** (una mejora de ~20x respecto a Python est√°ndar), su uso de memoria es proporcional al volumen de datos en el plan de ejecuci√≥n.
- Por otro lado, la estrategia de **Streaming con Orjson** permiti√≥ procesar el mismo dataset con apenas **~200MB de RAM**, demostrando que la eficiencia de memoria es posible sin sacrificar excesivamente el tiempo (9s vs 0.5s).

La implementaci√≥n exitosa de los **Git Hooks**, la **Observabilidad (Wide Events)** y la **Calidad de Software (Pytest)** garantizan que el c√≥digo no solo sea r√°pido, sino tambi√©n mantenible y profesional.
